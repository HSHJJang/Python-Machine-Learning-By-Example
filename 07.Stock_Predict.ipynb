{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **회귀 알고리즘을 활용한 주가예측**\n",
    "1. Linear Regression\n",
    "1. Regression Tree\n",
    "1. Random Forest\n",
    "1. **SVR** : Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **1 선형 회귀모델**\n",
    "Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **01 선형 회귀모델용 함수의 정의**\n",
    "선형 회귀모델 함수를 정의합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 현재 가중치를 이용하여 y_hat 예측값을 계산한다\n",
    "def compute_prediction(X, weights):\n",
    "    predictions = np.dot(X, weights)\n",
    "    return predictions # y_hat (X under weights : numpy.ndarray)\n",
    "\n",
    "# 매 단계에서 가중치를 업데이트 한다\n",
    "def update_weights_gd(X_train, y_train, weights, learning_rate):\n",
    "    predictions   = compute_prediction(X_train, weights)\n",
    "    weights_delta = np.dot(X_train.T, y_train - predictions)\n",
    "    m             = y_train.shape[0]\n",
    "    weights      += learning_rate / float(m) * weights_delta\n",
    "    return weights\n",
    "\n",
    "# 비용함수 J(w)를 계산하는 함수\n",
    "def compute_cost(X, y, weights):\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    cost        = np.mean((predictions - y) ** 2 / 2.0)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 시행 횟수 100번마다 비용함수를 출력\n",
    "def train_linear_regression(X_train, y_train, max_iter, learning_rate, fit_intercept=False, iter_print=100):\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train   = np.hstack((intercept, X_train))\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    for iteration in range(max_iter):\n",
    "        weights   = update_weights_gd(X_train, y_train, weights, learning_rate)\n",
    "        if iteration % iter_print == 0:\n",
    "            print(\"{:>4} th Learning Cost : {:.5f}\".format(iteration, compute_cost(X_train, y_train, weights)))\n",
    "    return weights # learned weights (numpy.ndarray)\n",
    "\n",
    "# 학습모델을 이용하여 새로운 입력결과를 예측하는 함수\n",
    "def predict(X, weights):\n",
    "    if X.shape[1] == weights.shape[0] - 1:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X         = np.hstack((intercept, X))\n",
    "    return compute_prediction(X, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **02 샘플 데이터 모델 적용하기**\n",
    "샘플데이터를 활용하여 선형모델을 학습하여 결과를 출력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 th Learning Cost : 5.57197\n",
      "  20 th Learning Cost : 0.08735\n",
      "  40 th Learning Cost : 0.08512\n",
      "  60 th Learning Cost : 0.08360\n",
      "  80 th Learning Cost : 0.08218\n"
     ]
    }
   ],
   "source": [
    "# A small example / 선형 모델의 학습\n",
    "X_train = np.array([[6], [2], [3], [4], [1], [5], [2], [6], [4], [7]])\n",
    "y_train = np.array([5.5, 1.6, 2.2, 3.7, 0.8, 5.2, 1.5, 5.3, 4.4, 6.8])\n",
    "weights = train_linear_regression(X_train, y_train, \n",
    "                                  max_iter = 100, \n",
    "                                  learning_rate = 0.01, \n",
    "                                  fit_intercept = True,\n",
    "                                  iter_print = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29545214, 3.31854448, 4.88184311, 2.67483328])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 모델을 사용하여, Test 데이터의 예측값을 출력\n",
    "X_test  = np.array([[1.3], [3.5], [5.2], [2.8]])\n",
    "predictions = predict(X_test, weights)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **03 Visualization**\n",
    "matplotlib로 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# 샘플로 학습한 모델의 성능을 확인한다\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train[:, 0], y_train,     marker = 'o', c = 'b')\n",
    "plt.scatter(X_test[:,  0], predictions, marker = '*', c = 'k')\n",
    "plt.xlabel('x'); plt.ylabel('y')\n",
    "plt.grid();      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **3 당뇨 데이터를 활용한 분석**\n",
    "datasets diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **01 Linear Regression 분석**\n",
    "선병모델을 활용하여 데이터를 분석합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "# 당뇨질환 데이터를 불러옵니다\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "print(diabetes.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 th Learning Cost : 2868.81478\n",
      " 500 th Learning Cost : 1430.92740\n",
      "1000 th Learning Cost : 1336.27657\n",
      "1500 th Learning Cost : 1322.76923\n",
      "2000 th Learning Cost : 1320.28422\n",
      "2500 th Learning Cost : 1319.62825\n",
      "3000 th Learning Cost : 1319.35963\n",
      "3500 th Learning Cost : 1319.20162\n",
      "4000 th Learning Cost : 1319.08757\n",
      "4500 th Learning Cost : 1318.99721\n"
     ]
    }
   ],
   "source": [
    "num_train = 300    # 전체 데이터 중 30개만 추출한다\n",
    "X_train = diabetes.data[:-num_train, :]\n",
    "y_train = diabetes.target[:-num_train]\n",
    "weights = train_linear_regression(X_train, y_train, \n",
    "                                  max_iter = 5000, \n",
    "                                  learning_rate = 1, \n",
    "                                  fit_intercept = True,\n",
    "                                  iter_print = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193.42570848 137.72256976 167.65318131 136.019608   151.92139125\n",
      " 128.3262914  254.47748265 103.87918261 119.03663996 109.89613264\n",
      " 229.74873066  65.43080473 130.38298521 123.051712    66.58434575\n",
      " 182.46327101  87.53832922 106.95812767 225.00888367  64.05852856]\n",
      "********************\n",
      "[233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.  49.  64.\n",
      "  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "num_test = 20\n",
    "X_test   = diabetes.data[-num_test:, :]\n",
    "y_test   = diabetes.target[-num_test:]\n",
    "predictions = predict(X_test, weights)\n",
    "print(predictions)\n",
    "print(\"*\"*20)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **02 SGD Regression 분석**\n",
    "**SGD** 기반의 회귀알고리즘을 사용하여 모델을 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178.3591412  160.8381357  169.56588684 113.11382513 177.06835844\n",
      " 139.45601921 230.69720001 117.01052482 134.5292982  132.15657588\n",
      " 202.48016752  94.50784735 140.28405432 129.96768194  83.37523757\n",
      " 177.99919258 136.81483352 139.05351912 183.52558058  88.71882609]\n",
      "0.4449478430613868\n"
     ]
    }
   ],
   "source": [
    "# Directly use SGDRegressor from scikit-learn\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "regressor = SGDRegressor(loss = 'squared_loss', \n",
    "                         penalty = 'l2', \n",
    "                         alpha = 0.0001, \n",
    "                         learning_rate = 'constant', \n",
    "                         eta0 = 0.01, max_iter = 1000)\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)\n",
    "print(regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **4 의사결정 회귀 트리모델**\n",
    "회귀트리라고 부르는 **의사결정 트리 회귀모델을** 만든다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **01 Regression Tree 모델 정의하기**\n",
    "회귀 Tree 에 필요로 하는 함수들을 정의합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6667\n",
      "0.5000\n",
      "type-semi: 10333.3333\n",
      "bedroom-2: 13000.0000\n",
      "bedroom-3: 16000.0000\n",
      "bedroom-4: 17500.0000\n",
      "bedroom-2: 15555.5556\n",
      "bedroom-3: 1666.6667\n",
      "bedroom-4: 6666.6667\n"
     ]
    }
   ],
   "source": [
    "# Mean squared error 값을 계산한다\n",
    "def mse(targets):\n",
    "    if targets.size == 0:\n",
    "        return 0\n",
    "    return np.var(targets)\n",
    "\n",
    "# 노드 분할 후, 자식 노드에 가중치를 반영하는 MSE 계산\n",
    "def weighted_mse(groups):\n",
    "    total = sum(len(group) for group in groups)\n",
    "    weighted_sum = 0.0\n",
    "    for group in groups:\n",
    "        weighted_sum += len(group) / float(total) * mse(group)\n",
    "    return weighted_sum\n",
    "\n",
    "print('{0:.4f}'.format(mse(np.array([1, 2, 3]))))\n",
    "print('{0:.4f}'.format(weighted_mse([np.array([1, 2, 3]), np.array([1, 2])])))\n",
    "print('type-semi: {0:.4f}'.format(weighted_mse([np.array([600, 400, 700]), np.array([700, 800])])))\n",
    "print('bedroom-2: {0:.4f}'.format(weighted_mse([np.array([700, 400]), np.array([600, 800, 700])])))\n",
    "print('bedroom-3: {0:.4f}'.format(weighted_mse([np.array([600, 800]), np.array([700, 400, 700])])))\n",
    "print('bedroom-4: {0:.4f}'.format(weighted_mse([np.array([700]), np.array([600, 700, 800, 400])])))\n",
    "print('bedroom-2: {0:.4f}'.format(weighted_mse([np.array([]), np.array([600, 400, 700])])))\n",
    "print('bedroom-3: {0:.4f}'.format(weighted_mse([np.array([400]), np.array([600, 700])])))\n",
    "print('bedroom-4: {0:.4f}'.format(weighted_mse([np.array([400, 600]), np.array([700])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree 생성과정\n",
    "def split_node(X, y, index, value):\n",
    "    x_index = X[:, index]\n",
    "    # 숫자형인 경우\n",
    "    if type(X[0, index]) in [int, float]:\n",
    "        mask = x_index >= value\n",
    "    else: # Feacture 형인경우\n",
    "        mask = x_index == value\n",
    "    left  = [X[~mask, :], y[~mask]]\n",
    "    right = [X[mask, :], y[mask]]\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree 분할과정을 Test 하고, 최소의 MSE결과로 생성한다\n",
    "def get_best_split(X, y):\n",
    "    best_index, best_value, best_score, children = None, None, 1e10, None\n",
    "    for index in range(len(X[0])):\n",
    "        for value in np.sort(np.unique(X[:, index])):\n",
    "            groups = split_node(X, y, index, value)\n",
    "            impurity = weighted_mse([groups[0][1], groups[1][1]])\n",
    "            if impurity < best_score:\n",
    "                best_index, best_value, best_score, children = index, value, impurity, groups\n",
    "    return {'index': best_index, 'value': best_value, 'children': children}\n",
    "\n",
    "# 중단 과정에 도달하면, 학습한 샘플의 평균을 Node에 할당한다\n",
    "def get_leaf(targets):\n",
    "    return np.mean(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 설정한 함수들을 사용하여, Tree를 생성합니다\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['children']\n",
    "    del (node['children'])\n",
    "    if left[1].size == 0:\n",
    "        node['right'] = get_leaf(right[1])\n",
    "        return \n",
    "    if right[1].size == 0:\n",
    "        node['left'] = get_leaf(left[1])\n",
    "        return\n",
    "    if depth >= max_depth: # 최대설정 깊이를 넘는지 확인\n",
    "        node['left'], node['right'] = get_leaf(left[1]), get_leaf(right[1])\n",
    "        return\n",
    "    # 왼쪽에 데이터가 많은지를 확인\n",
    "    if left[1].size <= min_size: \n",
    "        node['left'] = get_leaf(left[1])\n",
    "    else: # 데이터가 많으면 분할을 지속\n",
    "        result = get_best_split(left[0], left[1]) \n",
    "        result_left, result_right = result['children']\n",
    "        if result_left[1].size == 0:\n",
    "            node['left'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['left'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            node['left'] = result\n",
    "            split(node['left'], max_depth, min_size, depth + 1)\n",
    "    # 오른쪽에 데이터가 많은지 확인한다\n",
    "    if right[1].size <= min_size:\n",
    "        node['right'] = get_leaf(right[1])\n",
    "    else: # 데이터가 많으면 분할을 지속\n",
    "        result = get_best_split(right[0], right[1])\n",
    "        result_left, result_right = result['children']\n",
    "        if result_left[1].size == 0:\n",
    "            node['right'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['right'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            node['right'] = result\n",
    "            split(node['right'], max_depth, min_size, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 트리를 생성하는 함수를 구현\n",
    "def train_tree(X_train, y_train, max_depth, min_size):\n",
    "    root = get_best_split(X_train, y_train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화를 위한 함수를 정의합니다\n",
    "CONDITION = {'numerical': {'yes': '>=', 'no': '<'},\n",
    "             'categorical': {'yes': 'is', 'no': 'is not'}}\n",
    "\n",
    "def visualize_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        if type(node['value']) in [int, float]:\n",
    "            condition = CONDITION['numerical']\n",
    "        else:\n",
    "            condition = CONDITION['categorical']\n",
    "        print('{}|- X{} {} {}'.format(depth * '  ', node['index'] + 1, condition['no'], node['value']))\n",
    "        if 'left' in node:\n",
    "            visualize_tree(node['left'], depth + 1)\n",
    "        print('{}|- X{} {} {}'.format(depth * '  ', node['index'] + 1, condition['yes'], node['value']))\n",
    "        if 'right' in node:\n",
    "            visualize_tree(node['right'], depth + 1)\n",
    "    else:\n",
    "        print('{}[{}]'.format(depth * '  ', node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **02 Sample Data Learning**\n",
    "샘플 데이터로 학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- X1 is not detached\n",
      "  |- X2 < 3\n",
      "    [400.0]\n",
      "  |- X2 >= 3\n",
      "    [650.0]\n",
      "|- X1 is detached\n",
      "  [750.0]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([['semi', 3],\n",
    "                    ['detached', 2],\n",
    "                    ['detached', 3],\n",
    "                    ['semi', 2],\n",
    "                    ['semi', 4]], dtype=object)\n",
    "\n",
    "y_train = np.array([600, 700, 800, 400, 700])\n",
    "tree    = train_tree(X_train, y_train, 2, 2)\n",
    "visualize_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **03 Sklearn 모듈을 사용하여 예측 Learning**\n",
    "1. **보스턴 주택가격** 샘플 데이터로 학습을 진행합니다\n",
    "1. **DecisionTreeRegressor()** 모델을 생성합니다\n",
    "1. **RandomForestRegressor()** 모델을 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly use DecisionTreeRegressor from scikit-learn\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "boston['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, num_test = 400, 40\n",
    "X_train = boston.data[:-num_train, :]\n",
    "y_train = boston.target[:-num_train]\n",
    "X_test  = boston.data[-num_test:, :]\n",
    "y_test  = boston.target[-num_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.35 13.15 20.4  19.35 15.2  14.5  21.8  27.5  13.15 13.55 15.2  13.55\n",
      " 13.55 18.4  22.2  27.5  41.25 19.35 21.   22.2  20.6  19.95 18.9  13.55\n",
      " 13.55 18.9  18.9  19.35 20.9  19.35 18.45 20.4  22.2  18.45 20.6  23.9\n",
      " 20.6  22.3  22.3  18.9 ]\n",
      "[19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3 16.7 12.  14.6 21.4\n",
      " 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.   8.1 13.6 20.1 21.8\n",
      " 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 로 예측모델 만들기\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(max_depth = 10, \n",
    "                                  min_samples_split = 3)\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "# 모델로 예측한 결과와, Test 데이터 함께출력\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.49631667 13.60661667 15.20201667 17.61396818 16.17463333 18.2625\n",
      " 18.63135152 25.7807619  13.65298333 13.64867857 15.25173333 13.56462857\n",
      " 14.66328333 18.32165    19.79917771 25.18022857 29.3859119  19.20278485\n",
      " 18.19658333 19.65352619 17.81616104 19.40803333 19.26323333 17.9161\n",
      " 16.0564369  20.09843333 19.53632143 19.88540952 19.45571429 19.4685619\n",
      " 16.31768333 18.80917056 20.23481905 18.72032857 18.8358881  23.2602\n",
      " 21.50297619 26.8635619  25.90902857 22.11041667]\n",
      "[19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3 16.7 12.  14.6 21.4\n",
      " 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.   8.1 13.6 20.1 21.8\n",
      " 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 예측모델 만들기\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, \n",
    "                                  max_depth = 10, \n",
    "                                  min_samples_split = 3)\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **5 Support Vector Regression**\n",
    "최적화 모델을 위해 Quadrastic Programming 을 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **01 SVR 로 보스턴 주택가격을 예측한다**\n",
    "sklearn 모듈의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.51765924 11.52812846  8.56896669 11.60561208 14.44839328 15.77870783\n",
      " 16.47130184 18.38040736 10.44419889  9.63946423 13.82498705  4.37124727\n",
      " 11.00892456 11.76277798 16.7083346  18.43615048 19.09985084 17.96018562\n",
      " 17.16347788 17.94926849 14.08239627 16.92328514 11.10862519  8.04822255\n",
      "  4.95057639 11.65423644 14.11052094 20.99446569 21.10384132 19.3328556\n",
      " 15.60143705 19.20066307 20.60672814 18.67958819 19.39609013 21.65995868\n",
      " 21.0132411  23.29626544 22.53020883 21.05086548]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(C=0.1, epsilon=0.02, kernel='linear')\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **02 당뇨 데이터를 활용한 회귀 성능의 평가**\n",
    "**Grid search로** 데이터를 변환하여 모델을 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring model performance after hyperparameter tuning with grid search\n",
    "diabetes = datasets.load_diabetes()\n",
    "num_test = 30    # the last 30 samples as testing set\n",
    "X_train = diabetes.data[:-num_test, :]\n",
    "y_train = diabetes.target[:-num_test]\n",
    "X_test  = diabetes.data[-num_test:, :]\n",
    "y_test  = diabetes.target[-num_test:]\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-07, 1e-06, 1e-05],\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"eta0\": [0.001, 0.005, 0.01],\n",
    "    \"max_iter\": [300, 1000, 3000],\n",
    "    # \"n_iter\": [300, 1000, 3000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from warnings import simplefilter # import warnings filter\n",
    "# simplefilter(action='ignore', category=\"ConvergenceWarning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-07, 'eta0': 0.001, 'max_iter': 3000, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/momukji/Python/Python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=1e-07, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.001, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='constant', loss='squared_loss', max_iter=3000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그리드 탐색기술을 활용하여, 선형모델의 파라미터를 튜닝\n",
    "# stochastic_gradient.py:117 오류 메세지 삭제함\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regressor   = SGDRegressor(loss='squared_loss', learning_rate='constant')\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터를 출력\n",
    "print(grid_search.best_params_)\n",
    "regressor_best = grid_search.best_estimator_\n",
    "regressor_best\n",
    "# regressor_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([224.59629727, 125.01157037, 179.43110569, 170.7007692 ,\n",
       "       216.55508596, 149.25619168, 113.15857916,  91.9898621 ,\n",
       "       153.0267644 , 194.26250086, 191.9573202 , 159.67149136,\n",
       "       172.08003101,  98.48378094, 177.13474382, 135.62160924,\n",
       "       257.62187441, 105.24615368, 122.97413577, 126.44657486,\n",
       "       216.48738282,  73.67052182, 138.91055416, 122.88424774,\n",
       "        59.29094122, 188.71749798, 125.15667156, 135.49254336,\n",
       "       195.44713309,  60.85443476])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터를 활용하여 데이터 예측하기\n",
    "predictions = regressor_best.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 MSE : 2130.6472915839927\n",
      "모델의 MAE : 38.06468583506177\n",
      "모델의 R2  : 0.5864595403556934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"모델의 MSE : {}\\n모델의 MAE : {}\\n모델의 R2  : {}\".format(\n",
    "                      mean_squared_error(y_test, predictions),\n",
    "                      mean_absolute_error(y_test, predictions),\n",
    "                      r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **6 회귀 알고리즘으로 주가 예측하기**\n",
    "**Feature Engineering :** 파생변수 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **01 데이터 불러오기**\n",
    "Yahoo Finance API를 활용하여 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_datareader import data as pdr\n",
    "# import fix_yahoo_finance as yf\n",
    "# yf.pdr_override()  # 함수를 OverWriting 한다\n",
    "# data_raw         = pdr.get_data_yahoo(\"IDJ\", start=\"1997-01-01\", end=\"2018-11-30\")\n",
    "# data_raw.columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Adjusted Close\", \"Volume\"]\n",
    "# data_raw         = data_raw.reset_index()\n",
    "# data_raw.to_csv('./data/Stock.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #직접 다운로드 받은 파일로 작업 진행하기\n",
    "# df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "# df.columns = [\"Date\",\"Close\",\"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# df[\"Adjusted Close\"] = df[\"Close\"]\n",
    "# df = df[::-1]\n",
    "# df.to_csv('./data/Stock_nasdaq.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adjusted Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-29</th>\n",
       "      <td>18.89</td>\n",
       "      <td>68245.0</td>\n",
       "      <td>19.29</td>\n",
       "      <td>19.52</td>\n",
       "      <td>18.7850</td>\n",
       "      <td>18.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-30</th>\n",
       "      <td>18.87</td>\n",
       "      <td>254131.0</td>\n",
       "      <td>18.91</td>\n",
       "      <td>19.12</td>\n",
       "      <td>18.5400</td>\n",
       "      <td>18.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>19.06</td>\n",
       "      <td>175319.0</td>\n",
       "      <td>19.11</td>\n",
       "      <td>19.29</td>\n",
       "      <td>18.8900</td>\n",
       "      <td>19.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>14.97</td>\n",
       "      <td>822419.0</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.78</td>\n",
       "      <td>14.5701</td>\n",
       "      <td>14.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-02</th>\n",
       "      <td>15.34</td>\n",
       "      <td>304971.0</td>\n",
       "      <td>15.02</td>\n",
       "      <td>15.42</td>\n",
       "      <td>14.9000</td>\n",
       "      <td>15.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close    Volume   Open   High      Low  Adjusted Close\n",
       "Date                                                              \n",
       "2018-10-29  18.89   68245.0  19.29  19.52  18.7850           18.89\n",
       "2018-10-30  18.87  254131.0  18.91  19.12  18.5400           18.87\n",
       "2018-10-31  19.06  175319.0  19.11  19.29  18.8900           19.06\n",
       "2018-11-01  14.97  822419.0  18.78  18.78  14.5701           14.97\n",
       "2018-11-02  15.34  304971.0  15.02  15.42  14.9000           15.34"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_raw         = pd.read_csv('./data/Stock_nasdaq.csv')\n",
    "data_raw['Date'] = pd.to_datetime(data_raw['Date'])\n",
    "data_raw         = data_raw.set_index('Date')\n",
    "data_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **02 파생변수 생성하기**\n",
    "데이터의 **세밀한 분석을** 위하여 **파생변수를** 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering 함수의 정의\n",
    "def generate_features(df):\n",
    "    df_new = pd.DataFrame() # 기본정보 붙여넣기\n",
    "    for datum in [['open','Open',0],   ['open_1','Open',1], ['close_1','Close',1],\n",
    "                  ['high_1','High',1], ['low_1','Low',1],   ['volume_1','Volume',1]]:\n",
    "        df_new[datum[0]] = df[datum[1]].shift(datum[2])\n",
    "    # 평균 가격 변화를 기록한다\n",
    "    for datum in [['avg_price_5','Close',5], ['avg_price_30','Close',21],['avg_price_365','Close',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)\n",
    "    for datum in [['ratio_avg_price_5_30',  'avg_price_5', 'avg_price_30'],\n",
    "                  ['ratio_avg_price_5_365', 'avg_price_5', 'avg_price_365'],\n",
    "                  ['ratio_avg_price_30_365','avg_price_30','avg_price_365']]:\n",
    "        df_new[datum[0]] = df_new[datum[1]] / df_new[datum[2]]\n",
    "    # 평균 거래량 변화를 기록한다\n",
    "    for datum in [['avg_volume_5','Volume',5],['avg_volume_30','Volume',21],['avg_volume_365','Volume',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)\n",
    "    for datum in [['ratio_avg_volume_5_30',  'avg_volume_5', 'avg_volume_30'],\n",
    "                  ['ratio_avg_volume_5_365', 'avg_volume_5', 'avg_volume_365'],\n",
    "                  ['ratio_avg_volume_30_365','avg_volume_30','avg_volume_365']]:\n",
    "        df_new[datum[0]] = df_new[datum[1]] / df_new[datum[2]]\n",
    "    # 가격의 표준편차 변화를 기록한다\n",
    "    for datum in [['std_price_5','Close',5],['std_price_30','Close',21],['std_price_365','Close',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)\n",
    "    for datum in [['ratio_std_price_5_30',  'std_price_5', 'std_price_30'],\n",
    "                  ['ratio_std_price_5_365', 'std_price_5', 'std_price_365'],\n",
    "                  ['ratio_std_price_30_365','std_price_30','std_price_365']]:\n",
    "        df_new[datum[0]] = df_new[datum[1]] / df_new[datum[2]]\n",
    "    # 거래량의 표준편차 변화를 기록한다\n",
    "    for datum in [['std_volume_5','Volume',5],['std_volume_30','Volume',21],['std_volume_365','Volume',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)    \n",
    "    for datum in [['return_1',1],['return_5',5],['return_30',21],['return_365',252]]:\n",
    "        df_new[datum[0]] = ((df['Close'] - df['Close'].shift(datum[1])) / df['Close'].shift(datum[1])).shift(1)\n",
    "    for datum in [['moving_avg_5','return_1',5],['moving_avg_30','return_1',21],['moving_avg_365','return_1',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df_new[datum[1]], window=datum[2]).mean().shift(1)    \n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2265 entries, 2009-11-05 to 2018-11-02\n",
      "Data columns (total 4 columns):\n",
      "open       2265 non-null float64\n",
      "open_1     2265 non-null float64\n",
      "close_1    2265 non-null float64\n",
      "high_1     2265 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 88.5 KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 전처리 작업을 수행한다\n",
    "data = generate_features(data_raw)\n",
    "data.round(decimals=3).head(3)\n",
    "data.iloc[:,:4].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **03 주가예측 회귀모델 학습을 위한 전처리**\n",
    "1. 주가데이터 중 **필요한 부분을** 선별한다\n",
    "1. SGD 학습을 위해 선별한 자료를 **정규화** 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (테이블) : (1762, 34) \n",
      "Y_train (종가) : (1762,)\n"
     ]
    }
   ],
   "source": [
    "# 주가예측을 위한 학습 데이터를 호출\n",
    "import datetime\n",
    "start_train = datetime.datetime(2010, 1, 1, 0, 0)\n",
    "end_train   = datetime.datetime(2016, 12, 31, 0, 0)\n",
    "\n",
    "data_train = data.loc[start_train:end_train]\n",
    "X_columns  = list(data.drop(['close'], axis=1).columns)\n",
    "y_column   = 'close'\n",
    "X_train    = data_train[X_columns]\n",
    "y_train    = data_train[y_column]\n",
    "print(\"X_train (테이블) : {} \\nY_train (종가) : {}\".format(\n",
    "    X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test (테이블) : (251, 34) \n",
      "Y_test (종가) : (251,)\n"
     ]
    }
   ],
   "source": [
    "# 주가예측을 위한 Test 데이터를 호출\n",
    "start_test = datetime.datetime(2017, 1, 1, 0, 0)\n",
    "end_test   = datetime.datetime(2017, 12, 31, 0, 0)\n",
    "data_test  = data.loc[start_test:end_test]\n",
    "X_test     = data_test[X_columns]\n",
    "y_test     = data_test[y_column]\n",
    "print(\"X_test (테이블) : {} \\nY_test (종가) : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First experiment with linear regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# SGD 작업은 정밀한 작업으로 정규화 전처리를 한다\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **04 SGD 선형회귀 탐색을 진행한다**\n",
    "학습에 필요한 파라미터를 정의한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3e-05, 'eta0': 0.03}\n",
      "-0.19758323709074863\n"
     ]
    }
   ],
   "source": [
    "# SGD 선형회귀 모델을 학습한다\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "param_grid = { \"alpha\": [1e-5, 3e-5, 1e-4],\n",
    "               \"eta0\" : [0.01, 0.03, 0.1] }\n",
    "lr          = SGDRegressor(penalty='l2', n_iter_no_change=100)\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, n_jobs=-1,\n",
    "                           scoring = 'neg_mean_absolute_error',)\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "# 최대적합 파라미터를 출력한다\n",
    "print(grid_search.best_params_)\n",
    "lr_best = grid_search.best_estimator_\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.104\n",
      "MAE: 0.104\n",
      "R^2: 0.104\n"
     ]
    }
   ],
   "source": [
    "# SGD 모델의 샘플 예측결과를 출력한다\n",
    "predictions_lr = lr_best.predict(X_scaled_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print('MSE: {0:.3f}\\nMAE: {0:.3f}\\nR^2: {0:.3f}'.format(\n",
    "    mean_squared_error(y_test, predictions_lr),\n",
    "    mean_absolute_error(y_test, predictions_lr),\n",
    "    r2_score(y_test, predictions_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **05 Random Forest 모델 탐색을 진행한다**\n",
    "앙상블 기법을 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/momukji/Python/Python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = { \"max_depth\": [30, 50],    # 트리 최대깊이\n",
    "       \"min_samples_split\": [5, 10, 20]} # node 분할 최소갯수\n",
    "rf          = RandomForestRegressor(n_estimators=1000)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1,\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.571\n",
      "MAE: 0.571\n",
      "R^2: 0.571\n"
     ]
    }
   ],
   "source": [
    "rf_best = grid_search.best_estimator_\n",
    "predictions_rf = rf_best.predict(X_test)\n",
    "print('MSE: {0:.3f}\\nMAE: {0:.3f}\\nR^2: {0:.3f}'.format(\n",
    "    mean_squared_error(y_test, predictions_rf),\n",
    "    mean_absolute_error(y_test, predictions_rf),\n",
    "    r2_score(y_test, predictions_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **07 SVR 모델 탐색을 진행한다**\n",
    "선형 커널을 기반으로 한 Support Vector Regression 모델을 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally experiment with SVR\n",
    "from sklearn.svm import SVR\n",
    "param_grid = {\"C\": [100, 300, 1000],\n",
    "              \"epsilon\": [0.001, 0.0005, 0.0001]}\n",
    "svr = SVR(kernel='linear')\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, n_jobs=-1,\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "svr_best = grid_search.best_estimator_\n",
    "# print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 모델을 평가합니다\n",
    "predictions_svr = svr_best.predict(X_scaled_test)\n",
    "print('MSE: {0:.3f}\\nMAE: {0:.3f}\\nR^2: {0:.3f}'.format(\n",
    "    mean_squared_error(y_test, predictions_svr),\n",
    "    mean_absolute_error(y_test, predictions_svr),\n",
    "    r2_score(y_test, predictions_svr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dates       = data_test.index.values\n",
    "plot_truth, = plt.plot(dates, y_test, 'k')\n",
    "plot_lr,    = plt.plot(dates, predictions_lr, 'r')\n",
    "plot_rf,    = plt.plot(dates, predictions_rf, 'b')\n",
    "plot_svr,   = plt.plot(dates, predictions_svr, 'g')\n",
    "plt.legend([plot_truth, plot_lr, plot_rf, plot_svr], \n",
    "           ['Truth', 'Linear regression', 'Random forest', 'SVR'])\n",
    "plt.title('Stock price prediction vs truth')\n",
    "plt.grid(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
