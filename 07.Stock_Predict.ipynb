{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **회귀 알고리즘을 활용한 주가예측**\n",
    "1. Linear Regression\n",
    "1. Regression Tree\n",
    "1. Random Forest\n",
    "1. **SVR** : Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## **1 선형 회귀모델**\n",
    "Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **01 선형 회귀모델용 함수의 정의**\n",
    "선형 회귀모델 함수를 정의합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 현재 가중치를 이용하여 y_hat 예측값을 계산한다\n",
    "def compute_prediction(X, weights):\n",
    "    predictions = np.dot(X, weights)\n",
    "    return predictions # y_hat (X under weights : numpy.ndarray)\n",
    "\n",
    "# 매 단계에서 가중치를 업데이트 한다\n",
    "def update_weights_gd(X_train, y_train, weights, learning_rate):\n",
    "    predictions   = compute_prediction(X_train, weights)\n",
    "    weights_delta = np.dot(X_train.T, y_train - predictions)\n",
    "    m             = y_train.shape[0]\n",
    "    weights      += learning_rate / float(m) * weights_delta\n",
    "    return weights\n",
    "\n",
    "# 비용함수 J(w)를 계산하는 함수\n",
    "def compute_cost(X, y, weights):\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    cost        = np.mean((predictions - y) ** 2 / 2.0)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 시행 횟수 100번마다 비용함수를 출력\n",
    "def train_linear_regression(X_train, y_train, max_iter, learning_rate, fit_intercept=False, iter_print=100):\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train   = np.hstack((intercept, X_train))\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    for iteration in range(max_iter):\n",
    "        weights   = update_weights_gd(X_train, y_train, weights, learning_rate)\n",
    "        if iteration % iter_print == 0:\n",
    "            print(\"{:>4} th Learning Cost : {:.5f}\".format(iteration, compute_cost(X_train, y_train, weights)))\n",
    "    return weights # learned weights (numpy.ndarray)\n",
    "\n",
    "# 학습모델을 이용하여 새로운 입력결과를 예측하는 함수\n",
    "def predict(X, weights):\n",
    "    if X.shape[1] == weights.shape[0] - 1:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X         = np.hstack((intercept, X))\n",
    "    return compute_prediction(X, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **02 샘플 데이터 모델 적용하기**\n",
    "샘플데이터를 활용하여 선형모델을 학습하여 결과를 출력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 th Learning Cost : 5.57197\n",
      "  20 th Learning Cost : 0.08735\n",
      "  40 th Learning Cost : 0.08512\n",
      "  60 th Learning Cost : 0.08360\n",
      "  80 th Learning Cost : 0.08218\n"
     ]
    }
   ],
   "source": [
    "# A small example / 선형 모델의 학습\n",
    "X_train = np.array([[6], [2], [3], [4], [1], [5], [2], [6], [4], [7]])\n",
    "y_train = np.array([5.5, 1.6, 2.2, 3.7, 0.8, 5.2, 1.5, 5.3, 4.4, 6.8])\n",
    "weights = train_linear_regression(X_train, y_train, \n",
    "                                  max_iter = 100, \n",
    "                                  learning_rate = 0.01, \n",
    "                                  fit_intercept = True,\n",
    "                                  iter_print = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29545214, 3.31854448, 4.88184311, 2.67483328])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 모델을 사용하여, Test 데이터의 예측값을 출력\n",
    "X_test  = np.array([[1.3], [3.5], [5.2], [2.8]])\n",
    "predictions = predict(X_test, weights)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **03 Visualization**\n",
    "matplotlib로 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# 샘플로 학습한 모델의 성능을 확인한다\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train[:, 0], y_train,     marker = 'o', c = 'b')\n",
    "plt.scatter(X_test[:,  0], predictions, marker = '*', c = 'k')\n",
    "plt.xlabel('x'); plt.ylabel('y')\n",
    "plt.grid();      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## **3 당뇨 데이터를 활용한 분석**\n",
    "datasets diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **01 Linear Regression 분석**\n",
    "선병모델을 활용하여 데이터를 분석합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "# 당뇨질환 데이터를 불러옵니다\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "print(diabetes.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 th Learning Cost : 2868.81478\n",
      " 500 th Learning Cost : 1430.92740\n",
      "1000 th Learning Cost : 1336.27657\n",
      "1500 th Learning Cost : 1322.76923\n",
      "2000 th Learning Cost : 1320.28422\n",
      "2500 th Learning Cost : 1319.62825\n",
      "3000 th Learning Cost : 1319.35963\n",
      "3500 th Learning Cost : 1319.20162\n",
      "4000 th Learning Cost : 1319.08757\n",
      "4500 th Learning Cost : 1318.99721\n"
     ]
    }
   ],
   "source": [
    "num_train = 300    # 전체 데이터 중 30개만 추출한다\n",
    "X_train = diabetes.data[:-num_train, :]\n",
    "y_train = diabetes.target[:-num_train]\n",
    "weights = train_linear_regression(X_train, y_train, \n",
    "                                  max_iter = 5000, \n",
    "                                  learning_rate = 1, \n",
    "                                  fit_intercept = True,\n",
    "                                  iter_print = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193.42570848 137.72256976 167.65318131 136.019608   151.92139125\n",
      " 128.3262914  254.47748265 103.87918261 119.03663996 109.89613264\n",
      " 229.74873066  65.43080473 130.38298521 123.051712    66.58434575\n",
      " 182.46327101  87.53832922 106.95812767 225.00888367  64.05852856]\n",
      "********************\n",
      "[233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.  49.  64.\n",
      "  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "num_test = 20\n",
    "X_test   = diabetes.data[-num_test:, :]\n",
    "y_test   = diabetes.target[-num_test:]\n",
    "predictions = predict(X_test, weights)\n",
    "print(predictions)\n",
    "print(\"*\"*20)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **02 SGD Regression 분석**\n",
    "**SGD** 기반의 회귀알고리즘을 사용하여 모델을 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223.4154022  117.38210746 160.56443706 163.12850796 218.90727456\n",
      " 147.35148994  96.19776965  81.79071609 138.0515221  183.2810928\n",
      " 189.55744057 143.8012759  162.56480344 101.00017889 156.7050136\n",
      " 126.5492271  251.69846844  95.49978872 110.01272679 114.61216916\n",
      " 211.54126427  57.78711224 129.84900012 115.66093546  49.77239868\n",
      " 183.44431891 101.63943345 120.66681933 199.5451941   43.53574207]\n",
      "0.6596710542260882\n"
     ]
    }
   ],
   "source": [
    "# Directly use SGDRegressor from scikit-learn\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "regressor = SGDRegressor(loss = 'squared_loss', \n",
    "                         penalty = 'l2', \n",
    "                         alpha = 0.0001, \n",
    "                         learning_rate = 'constant', \n",
    "                         eta0 = 0.01, max_iter = 1000)\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)\n",
    "print(regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## **4 의사결정 회귀 트리모델**\n",
    "회귀트리라고 부르는 **의사결정 트리 회귀모델을** 만든다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **01 Regression Tree 모델 정의하기**\n",
    "회귀 Tree 에 필요로 하는 함수들을 정의합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6667\n",
      "0.5000\n",
      "type-semi: 10333.3333\n",
      "bedroom-2: 13000.0000\n",
      "bedroom-3: 16000.0000\n",
      "bedroom-4: 17500.0000\n",
      "bedroom-2: 15555.5556\n",
      "bedroom-3: 1666.6667\n",
      "bedroom-4: 6666.6667\n"
     ]
    }
   ],
   "source": [
    "# Mean squared error 값을 계산한다\n",
    "def mse(targets):\n",
    "    if targets.size == 0:\n",
    "        return 0\n",
    "    return np.var(targets)\n",
    "\n",
    "# 노드 분할 후, 자식 노드에 가중치를 반영하는 MSE 계산\n",
    "def weighted_mse(groups):\n",
    "    total = sum(len(group) for group in groups)\n",
    "    weighted_sum = 0.0\n",
    "    for group in groups:\n",
    "        weighted_sum += len(group) / float(total) * mse(group)\n",
    "    return weighted_sum\n",
    "\n",
    "print('{0:.4f}'.format(mse(np.array([1, 2, 3]))))\n",
    "print('{0:.4f}'.format(weighted_mse([np.array([1, 2, 3]), np.array([1, 2])])))\n",
    "print('type-semi: {0:.4f}'.format(weighted_mse([np.array([600, 400, 700]), np.array([700, 800])])))\n",
    "print('bedroom-2: {0:.4f}'.format(weighted_mse([np.array([700, 400]), np.array([600, 800, 700])])))\n",
    "print('bedroom-3: {0:.4f}'.format(weighted_mse([np.array([600, 800]), np.array([700, 400, 700])])))\n",
    "print('bedroom-4: {0:.4f}'.format(weighted_mse([np.array([700]), np.array([600, 700, 800, 400])])))\n",
    "print('bedroom-2: {0:.4f}'.format(weighted_mse([np.array([]), np.array([600, 400, 700])])))\n",
    "print('bedroom-3: {0:.4f}'.format(weighted_mse([np.array([400]), np.array([600, 700])])))\n",
    "print('bedroom-4: {0:.4f}'.format(weighted_mse([np.array([400, 600]), np.array([700])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree 생성과정\n",
    "def split_node(X, y, index, value):\n",
    "    x_index = X[:, index]\n",
    "    # 숫자형인 경우\n",
    "    if type(X[0, index]) in [int, float]:\n",
    "        mask = x_index >= value\n",
    "    else: # Feacture 형인경우\n",
    "        mask = x_index == value\n",
    "    left  = [X[~mask, :], y[~mask]]\n",
    "    right = [X[mask, :], y[mask]]\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree 분할과정을 Test 하고, 최소의 MSE결과로 생성한다\n",
    "def get_best_split(X, y):\n",
    "    best_index, best_value, best_score, children = None, None, 1e10, None\n",
    "    for index in range(len(X[0])):\n",
    "        for value in np.sort(np.unique(X[:, index])):\n",
    "            groups = split_node(X, y, index, value)\n",
    "            impurity = weighted_mse([groups[0][1], groups[1][1]])\n",
    "            if impurity < best_score:\n",
    "                best_index, best_value, best_score, children = index, value, impurity, groups\n",
    "    return {'index': best_index, 'value': best_value, 'children': children}\n",
    "\n",
    "# 중단 과정에 도달하면, 학습한 샘플의 평균을 Node에 할당한다\n",
    "def get_leaf(targets):\n",
    "    return np.mean(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 설정한 함수들을 사용하여, Tree를 생성합니다\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['children']\n",
    "    del (node['children'])\n",
    "    if left[1].size == 0:\n",
    "        node['right'] = get_leaf(right[1])\n",
    "        return \n",
    "    if right[1].size == 0:\n",
    "        node['left'] = get_leaf(left[1])\n",
    "        return\n",
    "    if depth >= max_depth: # 최대설정 깊이를 넘는지 확인\n",
    "        node['left'], node['right'] = get_leaf(left[1]), get_leaf(right[1])\n",
    "        return\n",
    "    # 왼쪽에 데이터가 많은지를 확인\n",
    "    if left[1].size <= min_size: \n",
    "        node['left'] = get_leaf(left[1])\n",
    "    else: # 데이터가 많으면 분할을 지속\n",
    "        result = get_best_split(left[0], left[1]) \n",
    "        result_left, result_right = result['children']\n",
    "        if result_left[1].size == 0:\n",
    "            node['left'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['left'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            node['left'] = result\n",
    "            split(node['left'], max_depth, min_size, depth + 1)\n",
    "    # 오른쪽에 데이터가 많은지 확인한다\n",
    "    if right[1].size <= min_size:\n",
    "        node['right'] = get_leaf(right[1])\n",
    "    else: # 데이터가 많으면 분할을 지속\n",
    "        result = get_best_split(right[0], right[1])\n",
    "        result_left, result_right = result['children']\n",
    "        if result_left[1].size == 0:\n",
    "            node['right'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['right'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            node['right'] = result\n",
    "            split(node['right'], max_depth, min_size, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 트리를 생성하는 함수를 구현\n",
    "def train_tree(X_train, y_train, max_depth, min_size):\n",
    "    root = get_best_split(X_train, y_train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화를 위한 함수를 정의합니다\n",
    "CONDITION = {'numerical': {'yes': '>=', 'no': '<'},\n",
    "             'categorical': {'yes': 'is', 'no': 'is not'}}\n",
    "\n",
    "def visualize_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        if type(node['value']) in [int, float]:\n",
    "            condition = CONDITION['numerical']\n",
    "        else:\n",
    "            condition = CONDITION['categorical']\n",
    "        print('{}|- X{} {} {}'.format(depth * '  ', node['index'] + 1, condition['no'], node['value']))\n",
    "        if 'left' in node:\n",
    "            visualize_tree(node['left'], depth + 1)\n",
    "        print('{}|- X{} {} {}'.format(depth * '  ', node['index'] + 1, condition['yes'], node['value']))\n",
    "        if 'right' in node:\n",
    "            visualize_tree(node['right'], depth + 1)\n",
    "    else:\n",
    "        print('{}[{}]'.format(depth * '  ', node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **02 Sample Data Learning**\n",
    "샘플 데이터로 학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- X1 is not detached\n",
      "  |- X2 < 3\n",
      "    [400.0]\n",
      "  |- X2 >= 3\n",
      "    [650.0]\n",
      "|- X1 is detached\n",
      "  [750.0]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([['semi', 3],\n",
    "                    ['detached', 2],\n",
    "                    ['detached', 3],\n",
    "                    ['semi', 2],\n",
    "                    ['semi', 4]], dtype=object)\n",
    "\n",
    "y_train = np.array([600, 700, 800, 400, 700])\n",
    "tree    = train_tree(X_train, y_train, 2, 2)\n",
    "visualize_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **03 Sklearn 모듈을 사용하여 예측 Learning**\n",
    "1. **보스턴 주택가격** 샘플 데이터로 학습을 진행합니다\n",
    "1. **DecisionTreeRegressor()** 모델을 생성합니다\n",
    "1. **RandomForestRegressor()** 모델을 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly use DecisionTreeRegressor from scikit-learn\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "boston['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, num_test = 400, 40\n",
    "X_train = boston.data[:-num_train, :]\n",
    "y_train = boston.target[:-num_train]\n",
    "X_test  = boston.data[-num_test:, :]\n",
    "y_test  = boston.target[-num_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.15 13.15 19.95 19.35 15.2  18.4  20.6  25.   13.15 13.55 15.2  13.55\n",
      " 13.55 17.5  23.9  25.   28.7  19.35 21.   22.2  20.6  19.95 19.8  14.35\n",
      " 14.35 19.8  19.8  19.35 20.9  19.35 18.45 19.95 23.9  18.45 20.6  23.9\n",
      " 20.6  22.3  22.3  19.8 ]\n",
      "[19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3 16.7 12.  14.6 21.4\n",
      " 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.   8.1 13.6 20.1 21.8\n",
      " 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 로 예측모델 만들기\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(max_depth = 10, \n",
    "                                  min_samples_split = 3)\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "# 모델로 예측한 결과와, Test 데이터 함께출력\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.07482302 20.70620893 21.48483586 20.1050772  21.11067479 26.32123489\n",
      " 21.4882648  28.42067619 27.92180298 20.98778262]\n",
      "[19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 예측모델 만들기\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, \n",
    "                                  max_depth = 10, \n",
    "                                  min_samples_split = 3)\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## **5 Support Vector Regression**\n",
    "최적화 모델을 위해 Quadrastic Programming 을 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **01 SVR 로 보스턴 주택가격을 예측한다**\n",
    "sklearn 모듈의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.59908201 19.32323741 21.16739294 18.53822876 20.1960847  23.74076575\n",
      " 22.65713954 26.98366295 25.75795682 22.69805145]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(C=0.1, epsilon=0.02, kernel='linear')\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **02 당뇨 데이터를 활용한 회귀 성능의 평가**\n",
    "**Grid search로** 데이터를 변환하여 모델을 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring model performance after hyperparameter tuning with grid search\n",
    "diabetes = datasets.load_diabetes()\n",
    "num_test = 30    # the last 30 samples as testing set\n",
    "X_train = diabetes.data[:-num_test, :]\n",
    "y_train = diabetes.target[:-num_test]\n",
    "X_test  = diabetes.data[-num_test:, :]\n",
    "y_test  = diabetes.target[-num_test:]\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-07, 1e-06, 1e-05],\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"eta0\": [0.001, 0.005, 0.01],\n",
    "    \"n_iter\": [300, 1000, 3000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 탐색기술을 활용하여, 선형모델의 파라미터를 튜닝\n",
    "# stochastic_gradient.py:117 오류 메세지 삭제함\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regressor   = SGDRegressor(loss='squared_loss', learning_rate='constant')\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터를 출력\n",
    "print(grid_search.best_params_)\n",
    "regressor_best = grid_search.best_estimator_\n",
    "regressor_best\n",
    "# regressor_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([226.87992709, 120.13398025, 163.88286289, 165.75072522,\n",
       "       221.54808156, 149.52675736,  99.28231346,  85.43045257,\n",
       "       143.12069837, 186.29470394, 190.24027462, 146.66442749,\n",
       "       165.68707985, 101.39732937, 161.94913912, 130.40137081,\n",
       "       256.25413987,  97.11328414, 112.73520373, 117.67339945,\n",
       "       215.08064765,  60.99175922, 133.28435024, 117.72819051,\n",
       "        51.76435141, 185.51611552, 106.4840507 , 124.9135482 ,\n",
       "       199.84919624,  46.1911042 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터를 활용하여 데이터 예측하기\n",
    "predictions = regressor_best.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 MSE : 18.58873175301942\n",
      "모델의 MAE : 3.45717352422849\n",
      "모델의 R2  : -0.7116538294324568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"모델의 MSE : {}\\n모델의 MAE : {}\\n모델의 R2  : {}\".format(\n",
    "                      mean_squared_error(y_test, predictions),\n",
    "                      mean_absolute_error(y_test, predictions),\n",
    "                      r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## **6 회귀 알고리즘으로 주가 예측하기**\n",
    "**Feature Engineering :** 파생변수 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **01 데이터 불러오기**\n",
    "Yahoo Finance API를 활용하여 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_datareader import data as pdr\n",
    "# import fix_yahoo_finance as yf\n",
    "# yf.pdr_override()  # 함수를 OverWriting 한다\n",
    "# data_raw         = pdr.get_data_yahoo(\"IDJ\", start=\"1997-01-01\", end=\"2018-11-30\")\n",
    "# data_raw.columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Adjusted Close\", \"Volume\"]\n",
    "# data_raw         = data_raw.reset_index()\n",
    "# data_raw.to_csv('./data/Stock.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #직접 다운로드 받은 파일로 작업 진행하기\n",
    "# df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "# df.columns = [\"Date\",\"Close\",\"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# df[\"Adjusted Close\"] = df[\"Close\"]\n",
    "# df = df[::-1]\n",
    "# df.to_csv('./data/Stock_nasdaq.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adjusted Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-29</th>\n",
       "      <td>18.89</td>\n",
       "      <td>68245.0</td>\n",
       "      <td>19.29</td>\n",
       "      <td>19.52</td>\n",
       "      <td>18.7850</td>\n",
       "      <td>18.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-30</th>\n",
       "      <td>18.87</td>\n",
       "      <td>254131.0</td>\n",
       "      <td>18.91</td>\n",
       "      <td>19.12</td>\n",
       "      <td>18.5400</td>\n",
       "      <td>18.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>19.06</td>\n",
       "      <td>175319.0</td>\n",
       "      <td>19.11</td>\n",
       "      <td>19.29</td>\n",
       "      <td>18.8900</td>\n",
       "      <td>19.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>14.97</td>\n",
       "      <td>822419.0</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.78</td>\n",
       "      <td>14.5701</td>\n",
       "      <td>14.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-02</th>\n",
       "      <td>15.34</td>\n",
       "      <td>304971.0</td>\n",
       "      <td>15.02</td>\n",
       "      <td>15.42</td>\n",
       "      <td>14.9000</td>\n",
       "      <td>15.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close    Volume   Open   High      Low  Adjusted Close\n",
       "Date                                                              \n",
       "2018-10-29  18.89   68245.0  19.29  19.52  18.7850           18.89\n",
       "2018-10-30  18.87  254131.0  18.91  19.12  18.5400           18.87\n",
       "2018-10-31  19.06  175319.0  19.11  19.29  18.8900           19.06\n",
       "2018-11-01  14.97  822419.0  18.78  18.78  14.5701           14.97\n",
       "2018-11-02  15.34  304971.0  15.02  15.42  14.9000           15.34"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_raw         = pd.read_csv('./data/Stock_nasdaq.csv')\n",
    "data_raw['Date'] = pd.to_datetime(data_raw['Date'])\n",
    "data_raw         = data_raw.set_index('Date')\n",
    "data_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **02 파생변수 생성하기**\n",
    "데이터의 **세밀한 분석을** 위하여 **파생변수를** 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering 함수의 정의\n",
    "def generate_features(df):\n",
    "    df_new = pd.DataFrame() # 기본정보 붙여넣기\n",
    "    for datum in [['open','Open',0],   ['open_1','Open',1], ['close_1','Close',1],\n",
    "                  ['high_1','High',1], ['low_1','Low',1],   ['volume_1','Volume',1]]:\n",
    "        df_new[datum[0]] = df[datum[1]].shift(datum[2])\n",
    "    # 평균 가격 변화를 기록한다\n",
    "    for datum in [['avg_price_5','Close',5], ['avg_price_30','Close',21],['avg_price_365','Close',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)\n",
    "    for datum in [['ratio_avg_price_5_30',  'avg_price_5', 'avg_price_30'],\n",
    "                  ['ratio_avg_price_5_365', 'avg_price_5', 'avg_price_365'],\n",
    "                  ['ratio_avg_price_30_365','avg_price_30','avg_price_365']]:\n",
    "        df_new[datum[0]] = df_new[datum[1]] / df_new[datum[2]]\n",
    "    # 평균 거래량 변화를 기록한다\n",
    "    for datum in [['avg_volume_5','Volume',5],['avg_volume_30','Volume',21],['avg_volume_365','Volume',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)\n",
    "    for datum in [['ratio_avg_volume_5_30',  'avg_volume_5', 'avg_volume_30'],\n",
    "                  ['ratio_avg_volume_5_365', 'avg_volume_5', 'avg_volume_365'],\n",
    "                  ['ratio_avg_volume_30_365','avg_volume_30','avg_volume_365']]:\n",
    "        df_new[datum[0]] = df_new[datum[1]] / df_new[datum[2]]\n",
    "    # 가격의 표준편차 변화를 기록한다\n",
    "    for datum in [['std_price_5','Close',5],['std_price_30','Close',21],['std_price_365','Close',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)\n",
    "    for datum in [['ratio_std_price_5_30',  'std_price_5', 'std_price_30'],\n",
    "                  ['ratio_std_price_5_365', 'std_price_5', 'std_price_365'],\n",
    "                  ['ratio_std_price_30_365','std_price_30','std_price_365']]:\n",
    "        df_new[datum[0]] = df_new[datum[1]] / df_new[datum[2]]\n",
    "    # 거래량의 표준편차 변화를 기록한다\n",
    "    for datum in [['std_volume_5','Volume',5],['std_volume_30','Volume',21],['std_volume_365','Volume',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df[datum[1]], window=datum[2]).mean().shift(1)    \n",
    "    for datum in [['return_1',1],['return_5',5],['return_30',21],['return_365',252]]:\n",
    "        df_new[datum[0]] = ((df['Close'] - df['Close'].shift(datum[1])) / df['Close'].shift(datum[1])).shift(1)\n",
    "    for datum in [['moving_avg_5','return_1',5],['moving_avg_30','return_1',21],['moving_avg_365','return_1',252]]:\n",
    "        df_new[datum[0]] = pd.DataFrame.rolling(df_new[datum[1]], window=datum[2]).mean().shift(1)    \n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2265 entries, 2009-11-05 to 2018-11-02\n",
      "Data columns (total 4 columns):\n",
      "open       2265 non-null float64\n",
      "open_1     2265 non-null float64\n",
      "close_1    2265 non-null float64\n",
      "high_1     2265 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 88.5 KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 전처리 작업을 수행한다\n",
    "data = generate_features(data_raw)\n",
    "data.round(decimals=3).head(3)\n",
    "data.iloc[:,:4].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **03 주가예측 회귀모델 학습을 위한 전처리**\n",
    "1. 주가데이터 중 **필요한 부분을** 선별한다\n",
    "1. SGD 학습을 위해 선별한 자료를 **정규화** 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (테이블) : (1762, 34) \n",
      "Y_train (종가) : (1762,)\n"
     ]
    }
   ],
   "source": [
    "# 주가예측을 위한 학습 데이터를 호출\n",
    "import datetime\n",
    "start_train = datetime.datetime(2010, 1, 1, 0, 0)\n",
    "end_train   = datetime.datetime(2016, 12, 31, 0, 0)\n",
    "\n",
    "data_train = data.loc[start_train:end_train]\n",
    "X_columns  = list(data.drop(['close'], axis=1).columns)\n",
    "y_column   = 'close'\n",
    "X_train    = data_train[X_columns]\n",
    "y_train    = data_train[y_column]\n",
    "print(\"X_train (테이블) : {} \\nY_train (종가) : {}\".format(\n",
    "    X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test (테이블) : (251, 34) \n",
      "Y_test (종가) : (251,)\n"
     ]
    }
   ],
   "source": [
    "# 주가예측을 위한 Test 데이터를 호출\n",
    "start_test = datetime.datetime(2017, 1, 1, 0, 0)\n",
    "end_test   = datetime.datetime(2017, 12, 31, 0, 0)\n",
    "data_test  = data.loc[start_test:end_test]\n",
    "X_test     = data_test[X_columns]\n",
    "y_test     = data_test[y_column]\n",
    "print(\"X_test (테이블) : {} \\nY_test (종가) : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First experiment with linear regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# SGD 작업은 정밀한 작업으로 정규화 전처리를 한다\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **04 SGD 선형회귀 탐색을 진행한다**\n",
    "학습에 필요한 파라미터를 정의한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3e-05, 'eta0': 0.03}\n"
     ]
    }
   ],
   "source": [
    "# SGD 선형회귀 모델을 학습한다\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "param_grid = { \"alpha\": [1e-5, 3e-5, 1e-4],\n",
    "               \"eta0\" : [0.01, 0.03, 0.1] }\n",
    "lr          = SGDRegressor(penalty='l2', n_iter=1000)\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, \n",
    "                           scoring = 'neg_mean_absolute_error')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "# 최대적합 파라미터를 출력한다\n",
    "print(grid_search.best_params_)\n",
    "lr_best = grid_search.best_estimator_\n",
    "# print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.101\n",
      "MAE: 0.101\n",
      "R^2: 0.101\n"
     ]
    }
   ],
   "source": [
    "# SGD 모델의 샘플 예측결과를 출력한다\n",
    "predictions_lr = lr_best.predict(X_scaled_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print('MSE: {0:.3f}\\nMAE: {0:.3f}\\nR^2: {0:.3f}'.format(\n",
    "    mean_squared_error(y_test, predictions_lr),\n",
    "    mean_absolute_error(y_test, predictions_lr),\n",
    "    r2_score(y_test, predictions_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **05 Random Forest 모델 탐색을 진행한다**\n",
    "앙상블 기법을 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markbaum/Python/python/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = { \"max_depth\": [30, 50],    # 트리 최대깊이\n",
    "       \"min_samples_split\": [5, 10, 20]} # node 분할 최소갯수\n",
    "rf          = RandomForestRegressor(n_estimators=1000)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, \n",
    "                           scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = grid_search.best_estimator_\n",
    "predictions_rf = rf_best.predict(X_test)\n",
    "print('MSE: {0:.3f}\\nMAE: {0:.3f}\\nR^2: {0:.3f}'.format(\n",
    "    mean_squared_error(y_test, predictions_rf),\n",
    "    mean_absolute_error(y_test, predictions_rf),\n",
    "    r2_score(y_test, predictions_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### **07 SVR 모델 탐색을 진행한다**\n",
    "선형 커널을 기반으로 한 Support Vector Regression 모델을 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally experiment with SVR\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "param_grid = {\"C\": [1000, 3000, 10000],\n",
    "              \"epsilon\": [0.00001, 0.00003, 0.0001]}\n",
    "svr = SVR(kernel='linear')\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, \n",
    "                           scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "svr_best = grid_search.best_estimator_\n",
    "# print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 모델을 평가합니다\n",
    "predictions_svr = svr_best.predict(X_scaled_test)\n",
    "print('MSE: {0:.3f}\\nMAE: {0:.3f}\\nR^2: {0:.3f}'.format(\n",
    "    mean_squared_error(y_test, predictions_svr),\n",
    "    mean_absolute_error(y_test, predictions_svr),\n",
    "    r2_score(y_test, predictions_svr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3e-05, 'eta0': 0.03}\n",
      "MSE: 0.099\n",
      "MAE: 0.216\n",
      "R^2: 0.919\n",
      "{'max_depth': 50, 'min_samples_split': 10}\n",
      "MSE: 0.579\n",
      "MAE: 0.621\n",
      "R^2: 0.527\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dates       = data_test.index.values\n",
    "plot_truth, = plt.plot(dates, y_test, 'k')\n",
    "plot_lr,    = plt.plot(dates, predictions_lr, 'r')\n",
    "plot_rf,    = plt.plot(dates, predictions_rf, 'b')\n",
    "plot_svr,   = plt.plot(dates, predictions_svr, 'g')\n",
    "plt.legend([plot_truth, plot_lr, plot_rf, plot_svr], \n",
    "           ['Truth', 'Linear regression', 'Random forest', 'SVR'])\n",
    "plt.title('Stock price prediction vs truth')\n",
    "plt.grid(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
